else{
cells <- unique(result$full[["Cell_id"]])
responders <- unique(result$peaks[["Cell_id"]])
non_responders <- cells %in% responders
non_responders <- unlist(purrr::map2(cells, non_responders, function(x,y) if(y == FALSE){x}))
shiny::selectInput(inputId = "non_resp_viz", "Non Responders", non_responders)
}
})
shiny::observeEvent(input$plot_button,{
cnames <- colnames(result$full)
back_estim_opt <- c("gam_fit", "background")
cnames_check <- back_estim_opt %in% cnames
back_var <- back_estim_opt[[which(cnames_check == TRUE)]]
output$plot_resp_viz <- renderPlot({
# Opérer un tri sur les cellules regarder comment j'ai fais pour responders
p <- cell_plot(result$full, result$peaks, var = "Mean_Grey", cell = input$resp_viz, line = back_var, show_peak = input$show_peaks_box)
p
})
})
shiny::observeEvent(input$plot_button_bis,{
cnames <- colnames(result$full)
back_estim_opt <- c("gam_fit", "background")
cnames_check <- back_estim_opt %in% cnames
back_var <- back_estim_opt[[which(cnames_check == TRUE)]]
output$plot_resp_viz <- renderPlot({
p <- cell_plot(result$full, result$peaks, var = "Mean_Grey", cell = input$non_resp_viz, line = back_var, show_peak = input$show_peaks_box)
p
})
})
output$clustering_var <- shiny::renderUI({
if(dim(calipR::checkTable(paste(project$dir_path,project$db_file, sep ="/"), "'df_final'"))[1] == 0) {
print( "dim == 0")
}
else{
list_var <- names(result$full)
shiny::selectInput(inputId = "clustvar", "Variable used for clustering", list_var)
}
})
shiny::observeEvent(input$set_seed, {
if(input$set_seed){
output$seed_field <- shiny::renderUI({
shiny::textInput("seed", "Enter Seed Value")
})
}
else{
output$seed_field <- NULL
}
})
shiny::observeEvent(input$clustplot_button, {
responding_cells <- unique(result$peaks[["Cell_id"]])
dt <- result$full[Cell_id %in% responding_cells]
final <- prepareClustData(dt, input$clustvar, norm = input$normclust)
if(input$set_seed){
set.seed(as.integer(input$seed))
}
clust_res <- dtwclust::tsclust(final, type = "partitional", k = as.integer(input$nclust), distance = input$dist_type,
centroid = "dba")
output$clustplot <- shiny::renderPlot({
p <- plot(clust_res, type="sc")
p
})
})
}
shiny::shinyApp(ui, server)
}
#' downstream_analysis
#'
#' A wrapper function used in the graphical user interface to process the already prepared data.
#' Can be used as a one line function to run the complete workflow on the output from prepareData or prepareata_track.
#'
#' @param data
#' @param moving_thresh
#' @param outlier_thresh
#' @param mean_width
#' @param DPA_width
#' @param mean_width_diff
#' @param method
#' @param norm_var
#' @param norm_width
#' @param lambda
#' @param gam
#' @param constraint
#' @param threshold
#' @param deconvolve_var
#' @param borders_range
#' @param time_thresh
#' @param compare_groups
#' @param CN_DPA_width
#' @param false_pos
#' @param one_cell
#' @param simulation
#' @param pattern_matching
#' @param posBank
#' @param negBank
#' @param windows
#' @param steps
#'
#' @return
#' @export
#'
#' @examples
downstream_analysis <- function(data, moving_thresh = 0.1, outlier_thresh = 2, mean_width = 20, DPA_width = 10, CN_DPA_width = 20,
mean_width_diff = 10, method = "gam", norm_var = "gam",
norm_width = 10, lambda = 100,
gam = 0.97, constraint = T, z_thresh = 3, delta_thresh = 0,
deconvolve_var = "gam_detrended", borders_range = 50,
time_thresh = 1, compare_groups = FALSE, false_pos = c(TRUE, FALSE), one_cell = FALSE, simulation = FALSE,
pattern_matching = FALSE, posBank = list(),
negBank = list(), windows = c(30,70,100)) {
lambda <- as.numeric(lambda)
gam <- as.numeric(gam)
if(one_cell == FALSE){
shiny::withProgress(message = "Analyzing Full Dataset", value = 0, detail = "Cleaning Data", {
if(pattern_matching == TRUE){
clean <-clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff, method = "back")
shiny::incProgress(1/5, detail = "Estimating Background")
back <- patDetectR(clean, windows, new_len = 30, posBank,
negBank, Var = "Mean_Grey")
back <- backEstimatR(clean, back)
shiny::incProgress(1/5, detail = "Normalizing Data")
norm <- norm_df(back, var = "back", width = norm_width)
shiny::incProgress(1/5, detail = "Performing Deconvolution")
deconvolved <- deconvolve(norm, lambda = lambda, gam = gam, constraint = constraint,
threshold = z_thresh, delta_threshold = delta_thresh, var = "background_detrended")
}
if(pattern_matching == FALSE){
clean <- clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff)
shiny::incProgress(1/5, detail = "Estimating Background")
back <- calipR::backEstimate(clean, method = method)
shiny::incProgress(1/5, detail = "Normalizing Data")
norm <- calipR::norm_df(back, var = norm_var, width = norm_width)
shiny::incProgress(1/5, detail = "Performing Deconvolution")
deconvolved <- deconvolve(norm, lambda = lambda, gam = gam, constraint = constraint,
threshold = z_thresh, delta_threshold = delta_thresh, var = deconvolve_var)
}
if(length(deconvolved[[1]]$Cell_id) != 0){
if(false_pos == TRUE){
shiny::incProgress(1/5, detail = "Removing Estimated False Positives")
deconvolved <- keep_best_peaks(deconvolved)
}
shiny::incProgress(1/5, detail = "Computing Statistics")
res <- Analyze_Responses(deconvolved[[1]], clean, compare_groups = compare_groups,
one_cell = one_cell, simulation = simulation)
}
})
}
if(one_cell == TRUE){
shiny::withProgress(message = "Testing New Parameters", value = 0, detail = "Performing Deconvolution", {
if(pattern_matching == TRUE){
clean <- clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff, method = "back")
back <- patDetectR(clean, windows, new_len = 30, posBank,
negBank, Var = "Mean_Grey")
back <- backEstimatR(clean, back)
norm <- norm_df(back, var = "back", width = norm_width)
deconvolved <- deconvolve(norm, lambda = lambda,gam = gam,
constraint = constraint,threshold = z_thresh,
delta_threshold = delta_thresh,
var = "background_detrended")
}
if(pattern_matching == FALSE){
clean <- clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff)
back <- backEstimate(clean, method = method)
norm <- norm_df(back, var = norm_var, width = norm_width)
deconvolved <- deconvolve(norm, lambda = lambda, gam = gam,
constraint = constraint,threshold = z_thresh,
delta_threshold = delta_thresh,
var = deconvolve_var)
}
if(length(deconvolved[[1]]$Cell_id) != 0){
if(false_pos == TRUE){
deconvolved <- keep_best_peaks(deconvolved)
}
}
res <- "NO RES"
norm <- data
})
}
return(list(deconvolved[[1]], deconvolved[[2]], res))
}
#' @param pattern_matching
#' @param posBank
#' @param negBank
#' @param windows
#' @param steps
#'
#' @return
#' @export
#'
#' @examples
downstream_analysis <- function(data, moving_thresh = 0.1, outlier_thresh = 2, mean_width = 20, DPA_width = 10, CN_DPA_width = 20,
mean_width_diff = 10, method = "gam", norm_var = "gam",
norm_width = 10, lambda = 100,
gam = 0.97, constraint = T, z_thresh = 3, delta_thresh = 0,
deconvolve_var = "gam_detrended", borders_range = 50,
time_thresh = 1, compare_groups = FALSE, false_pos = c(TRUE, FALSE), one_cell = FALSE, simulation = FALSE,
pattern_matching = FALSE, posBank = list(),
negBank = list(), windows = c(30,70,100)) {
lambda <- as.numeric(lambda)
gam <- as.numeric(gam)
if(one_cell == FALSE){
shiny::withProgress(message = "Analyzing Full Dataset", value = 0, detail = "Cleaning Data", {
if(pattern_matching == TRUE){
clean <-clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff, method = "back")
shiny::incProgress(1/5, detail = "Estimating Background")
back <- patDetectR(clean, windows, new_len = 30, posBank,
negBank, Var = "Mean_Grey")
back <- backEstimatR(clean, back)
shiny::incProgress(1/5, detail = "Normalizing Data")
norm <- norm_df(back, var = "back", width = norm_width)
shiny::incProgress(1/5, detail = "Performing Deconvolution")
deconvolved <- deconvolve(norm, lambda = lambda, gam = gam, constraint = constraint,
threshold = z_thresh, delta_threshold = delta_thresh, var = "background_detrended")
}
if(pattern_matching == FALSE){
clean <- clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff)
shiny::incProgress(1/5, detail = "Estimating Background")
back <- calipR::backEstimate(clean, method = method)
shiny::incProgress(1/5, detail = "Normalizing Data")
norm <- calipR::norm_df(back, var = norm_var, width = norm_width)
shiny::incProgress(1/5, detail = "Performing Deconvolution")
deconvolved <- deconvolve(norm, lambda = lambda, gam = gam, constraint = constraint,
threshold = z_thresh, delta_threshold = delta_thresh, var = deconvolve_var)
}
if(length(deconvolved[[1]]$Cell_id) != 0){
if(false_pos == TRUE){
shiny::incProgress(1/5, detail = "Removing Estimated False Positives")
deconvolved <- keep_best_peaks(deconvolved)
}
shiny::incProgress(1/5, detail = "Computing Statistics")
res <- Analyze_Responses(deconvolved[[1]], clean, compare_groups = compare_groups,
one_cell = one_cell, simulation = simulation)
}
})
}
if(one_cell == TRUE){
shiny::withProgress(message = "Testing New Parameters", value = 0, detail = "Performing Deconvolution", {
if(pattern_matching == TRUE){
clean <- clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff, method = "back")
back <- patDetectR(clean, windows, new_len = 30, posBank,
negBank, Var = "Mean_Grey")
back <- backEstimatR(clean, back)
norm <- norm_df(back, var = "back", width = norm_width)
deconvolved <- deconvolve(norm, lambda = lambda,gam = gam,
constraint = constraint,threshold = z_thresh,
delta_threshold = delta_thresh,
var = "background_detrended")
}
if(pattern_matching == FALSE){
clean <- clean_data(data, moving_thresh, outlier_thresh, mean_width,
CN_DPA_width, DPA_width, mean_width_diff)
back <- backEstimate(clean, method = method)
norm <- norm_df(back, var = norm_var, width = norm_width)
deconvolved <- deconvolve(norm, lambda = lambda, gam = gam,
constraint = constraint,threshold = z_thresh,
delta_threshold = delta_thresh,
var = deconvolve_var)
}
if(length(deconvolved[[1]]$Cell_id) != 0){
if(false_pos == TRUE){
deconvolved <- keep_best_peaks(deconvolved)
}
}
res <- "NO RES"
norm <- data
})
}
return(list(deconvolved[[1]], deconvolved[[2]], res))
}
#' @param posBank
#' @param negBank
#' @param new_len
#' @param Var
#' @param Norm
#'
#' @return A data table containing the ratio for each index and related informations
#' @export
#'
#' @examples
patDetectR <- function(dt, window, posBank, negBank, new_len, Var, Norm = TRUE) {
# Computing steps for rolling subsequencing:
step <- as.integer(sqrt(window))* 2
# Subsequencing, Interpolation and Normalization
data <- subinoR(dt, window, step, new_len, posBank, negBank, var = Var, norm = Norm)
# DTW distance computing between each subsequence and each pattern
pos <- distcomputR(data[[2]], data[[1]], step, window)
neg <- distcomputR(data[[3]], data[[1]], step, window)
# Median distance extraction by index and Ratio between pos and neg median dist
res <- mdRatio(pos, neg)
return(res)
}
#' @param var
#'
#' @return a list containing a data table with all the interpolated and
#' normalized subsequences for each trace, two data tables with the interpolated
#' and normalized positive and negative banks and a list with the number of subsequences
#' for each specified subsequence window.
#'
#' @export
#'
#' @examples
subinoR <- function(dt, window, step, new_len, posBank, negBank, norm = TRUE, var = "Mean_Grey"){
# Subsequence segmentation for each chosen window, for each cell in the dt :
# Extracting the minimum time series size to resize them
resizing <- min(unlist(lapply(split(dt, dt$coverslip), function(x) x[, .N ,by = Cell_id]$N[[1]])))
subseq_list <- lapply(seq(1,length(window)), function(x)dt[, subsequencR(get(var),
window[[x]], step[[x]], resizing), by = Cell_id])
n_sub_seq_list <- lapply(subseq_list, function(x) length(names(x)) -1)
# Intrerpolation to standardize requests and banks lengths:
interp_patBank2 <- data.table::as.data.table(interpolR(posBank, new_len))
interp_anomBank <- data.table::as.data.table(interpolR(negBank, new_len))
interp_subseq_vec_list <- lapply(subseq_list, function(x)
x[, data.table::as.data.table(interpolR(as.list(.SD),
new_len)), by = Cell_id, .SDcols = -c("Cell_id")])
# If wanted, z-normalization of each bank and requests :
if(norm == TRUE){
interp_patBank2 <- as.matrix(interp_patBank2[, lapply(.SD, function(x)
matrixprofiler::znorm(x))])
interp_anomBank <- as.matrix(interp_anomBank[, lapply(.SD, function(x)
matrixprofiler::znorm(x))])
interp_subseq_vec_list <- lapply(interp_subseq_vec_list, function(x)
x[, lapply(.SD, function(x)matrixprofiler::znorm(x)),
by = Cell_id])
}
return(list(interp_subseq_vec_list, interp_patBank2, interp_anomBank, n_sub_seq_list))
}
#' Computes the median distance ratio between the best match in the positive and
#' the negative banks, for each index.
#'
#' @param pos
#' @param neg
#'
#' @return a data table with the median ratio in one column
#' @export
#'
#' @examples
mdRatio <- function(pos, neg){
pos[, neg_val := neg$value]
pos <- pos[, matFillR_bis_bis(.SD),by = .(win, Cell_id)]
pos[ , c("min_val", "min_neg_val") := list(min(.SD$pos_val),min(.SD$neg_val)) ,
by = .(Cell_id, idx), .SDcols = c("pos_val","neg_val")]
pos2 <- pos[min_val == pos_val | min_neg_val == neg_val][order(Cell_id, idx)]
pos2[, min_min := min(.SD) , by = .(Cell_id, idx,win), .SDcols = c("min_val", "min_neg_val")]
pos2 <- pos2[pos_val == min_min |neg_val == min_min]
pos2[, ratio := pos_val/neg_val]
return(pos2)
}
#'
#' @param patMat
#' @param subseqMat
#' @param step
#' @param window
#'
#' @return
#' @export
#'
#' @examples
distcomputR <- function(patMat, subseqMat, step, window){
pos_dist_list <- lapply(subseqMat, function(x) x[,  lapply(.SD, function(y)
rucrdtw::ucrdtw_mv(patMat, y, dtwwindow =0.05)$distance), by = Cell_id,
.SDcols = -c("Cell_id")])
col_len_list <- lapply(pos_dist_list, names)
pos_dist_long_list <- purrr::map2(pos_dist_list, col_len_list, function(x,y)
data.table::melt(x, measure.vars = 2:length(y))[order(Cell_id)])
lapply(seq(1,length(pos_dist_long_list)), function(x)
pos_dist_long_list[[x]][, variable2 := seq(1,.N*step[[x]], by = step[[x]]), by = Cell_id])
# Adding the sequences indices
lapply(seq(1,length(pos_dist_long_list)), function(x)
pos_dist_long_list[[x]][, sub_seq := .(.(seq(0,window[[x]]) + variable2)), by = .(Cell_id, variable2)])
lapply(seq(1,length(pos_dist_long_list)), function(x) pos_dist_long_list[[x]][, win := window[[x]]])
final <- do.call(rbind, pos_dist_long_list)
return(final)
}
#' Creates a matrix to align all the distance values obtained with the different
#' subsequences together with the indexes of the original trace. For each index,
#' the kept distance is the median across all the overlapping distances
#'
#' @param dt
#'
#' @return
#' @export
#'
#' @examples
matFillR_bis_bis <- function(dt){
idx <- matrix(unlist(dt$sub_seq), ncol = length(dt$sub_seq))
mat_pos <- matrix(nrow = length(dt$sub_seq), ncol = max(unlist(dt$sub_seq)))
mat_neg <- mat_pos
for(i in seq(1,length(dt$value))){
mat_pos[i,idx[,i]] <- dt$value[i]
mat_neg[i,idx[,i]] <- dt$neg_val[i]
}
pos_val <- robustbase::colMedians(mat_pos, na.rm = TRUE)
neg_val <- robustbase::colMedians(mat_neg, na.rm = TRUE)
dt_pos <- data.table::as.data.table(pos_val)[, c("neg_val", "idx") := list( neg_val, seq(1,.N))]
return(dt_pos)
}
#' Vectorized function to subset equal length windows from a longer time series.
#'
#' @param time_series
#' @param window
#' @param step
#'
#' @return a data table of subsequences
#' @export
#'
#' @examples
subsequencR <- function(time_series, window, step, resizing){
if(window > length(time_series)){
stop("Window length cannot be bigger than time series length")
}
if(step > length(time_series)){
stop("step length cannot be bigger than time series length")
}
time_series <- interpolR(list(time_series), resizing)
s0 <- seq(0,window)
# définir un itérateur qui va de 1 à longueur du tracé à découper (l) - m
l <- length(time_series)
it <- seq(1,l-window, by = step)
sub_seqs <- lapply(it, function(x) s0 + x)
# Creating a 2-column dt: 1 is the base sequence the other contains a list with all subsequences
sub_dt <- data.table::data.table("orig_seq" = list(time_series),
"sub_seq" = sub_seqs)[, id := seq(1,.N)]
# Vectorized implementation to subset subsequences
sub_dt[, sub_seq_final := .(.(unlist(.(.(orig_seq)[1])[[1]])[sub_seq[[1]]])), by = id]
dt <- data.table::setDT(sub_dt$sub_seq_final)
return(dt)
}
#' Takes a list of time series patterns and the length to which each must be
#' linearly interpolated
#'
#' @param list
#' @param len
#'
#' @return a matrix where each initial pattern has length len.
#' @export
#'
#' @examples
interpolR <- function(list, len, type = c("one","multiple")){
dt <- data.table::data.table(list)[, id := seq(1,.N)]
dt[,  final := .(.(approx(seq(1,length(unlist(.(.(list)[1])[[1]]))),
unlist(.(.(list)[1])[[1]]), method = "linear", ties = mean,
n = len)$y)), by = id]
mat <- do.call(cbind, dt$final)
return(mat)
}
#'
#' @param dt
#'
#' @param patdet_out
#'
#' @return a data table with the estimated background trace in a new column called
#' "background" and the detrended Mean Grey values in a column called "background detrended"
#' @export
#'
#' @examples
backEstimatR <- function(dt, patdet_out) {
patdet_out[, smooth_min_ratio := gplots::wapply(seq(1,.N), ratio,fun = min,
n = .N,  width = 20, method = "nobs")[[2]], by = Cell_id]
patdet_out[, time_frame := seq(1,.N), by = Cell_id]
data.table::setkey(dt, Cell_id, time_frame)
data.table::setkey(patdet_out, Cell_id, time_frame)
full_dt <- patdet_out[dt, on = c("Cell_id", "time_frame")]
full_dt[, signal := ifelse(smooth_min_ratio > 0.95 & smooth_Diff < 2*median(smooth_Diff),
'Noise', ifelse(smooth_min_ratio < 0.95 & local_mean > median(local_mean),  'Signal', NA)), by = Cell_id]
full_dt[, rolling_min_new := gplots::wapply(time_frame, Mean_Grey,fun = function(x) quantile(x, probs = 0.2, names = FALSE),
n = length(time_frame),  width = 30, method = "nobs")[[2]], by = Cell_id]
full_dt[, mean_grey_wo_peaks_new_new := ifelse(signal %in% c("Noise", NA), Mean_Grey, NA), by = Cell_id]
# If all values have been removed : fix the first and last values
full_dt[, mean_grey_wo_peaks_new_new := ifelse(time_frame %in% c(1,.N), rolling_min_new, mean_grey_wo_peaks_new_new), by = Cell_id]
# Linear interpolation between removed values
full_dt[,labels := cumsum(!is.na(mean_grey_wo_peaks_new_new)) , by = Cell_id]
full_dt[,labels2 := seq(1,.N) , by = .(Cell_id, labels)]
full_dt[,Diff := dplyr::lead(labels) - labels , by = Cell_id]
full_dt[,lag_roll_min := dplyr::lag(rolling_min_new) , by = Cell_id]
full_dt[,mean_grey_wo_peaks_new_new := ifelse(labels2 == 1 & Diff == 0,
lag_roll_min[[1]],
ifelse(labels2 == .N &
is.na(mean_grey_wo_peaks_new_new),lag_roll_min[[.N]],mean_grey_wo_peaks_new_new)),
by = .(Cell_id, labels)]
full_dt[, mean_grey_wo_peaks_new_new := ifelse(time_frame %in% c(1,.N), rolling_min_new, mean_grey_wo_peaks_new_new), by = Cell_id]
full_dt[, mean_grey_wo_peaks_new_new := approxfun(which(!is.na(mean_grey_wo_peaks_new_new)), na.omit(mean_grey_wo_peaks_new_new))(seq_along(mean_grey_wo_peaks_new_new)), by = Cell_id]
# Background estimation through a rolling median (1st round) :
full_dt[, rolling_med_new := gplots::wapply(time_frame, mean_grey_wo_peaks_new_new,fun = median,
n = length(time_frame),  width = 30, method = "nobs")[[2]], by = Cell_id]
full_dt[, below_med := ifelse(mean_grey_wo_peaks_new_new < rolling_med_new, TRUE, FALSE), by = Cell_id]
# Removing values upper the rolling median :
full_dt[, mean_grey_wo_peaks_new_new := ifelse(below_med == TRUE, mean_grey_wo_peaks_new_new, NA)]
full_dt[, mean_grey_wo_peaks_new_new := ifelse(time_frame %in% c(1,.N), rolling_min_new, mean_grey_wo_peaks_new_new), by = Cell_id]
# Linear interpolation of removed values :
full_dt[, mean_grey_wo_peaks_new_new := approxfun(which(!is.na(mean_grey_wo_peaks_new_new)), na.omit(mean_grey_wo_peaks_new_new))(seq_along(mean_grey_wo_peaks_new_new)), by = Cell_id]
# Last rolling median to estimate the background
full_dt[, background := gplots::wapply(time_frame, mean_grey_wo_peaks_new_new,fun = median,
n = length(time_frame),  width = 30, method = "nobs")[[2]], by = Cell_id]
full_dt[, background_detrended := Mean_Grey - background, by = .(Cell_id, coverslip)]
final_dt <- full_dt[, .(Cell_id, Mean_Grey, time_frame, time_seconds, stimulus,
coverslip,  group, Stimulation, marker_positive, local_mean,
first_derivative, smooth_Diff, signal, background, background_detrended,
Time_frame_stim
)]
return(final_dt)
}
guigui()
guigui()
guigui()
guigui()
guigui()
