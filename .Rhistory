#' @param data the whole output from find_peaks function
#' @param range
#'
#' @return the same objects with an added column named True_Peaks which is TRUE if the peak is kept, FALSE if not
#' @export
#'
#' @examples
keep_best_peaks <- function(data, range){
data[[1]] <- data.table::setDT(data[[1]])[, True_peak := Max_peak_smooth_z == max(Max_peak_smooth_z), by = list(Cell_id, Max_peak_stimulus)]
data[[2]] <- data.table::setDT(data[[2]])[, True_peak := smooth_z == max(smooth_z), by = list(Cell_id, stimulus)]
print(data[[1]])
print(data[[2]])
peaks_data  <- data[[1]][data[[1]]$True_peak == TRUE,]
peaks_list <- split(peaks_data,cumsum(1:nrow(peaks_data) %in% seq(1:nrow(peaks_data))))
#peaks_list <- lapply(peaks_data, function(x) x[, triangleRatio := triangleRatio(full_data, x)])
#peaks_list <- lapply(peaks_list, function(x)  x[, triangleRatio := triangleRatio(data[[2]], x)[[1]]])
#peaks_list <- lapply(peaks_list, function(x) x[, trianglePoints :=  triangleRatio(data[[2]], x)[2]])
#peaks_list <- lapply(peaks_list, function(x) x[, posArea :=  triangleRatio(data[[2]], x)[3]])
#peaks_list <- lapply(peaks_list, function(x) x[, negArea :=  triangleRatio(data[[2]], x)[4]])
peaks_list <- lapply(peaks_list, function(x) x[, infValue :=  inferiorValues(x, data[[2]])])
#peaks_list <- lapply(peaks_list, function(x) x[, infValue_D :=  inferiorValues_lag(x, data[[2]])])
#peaks_list <- lapply(peaks_list, function(x) x[, infValue_D :=  inferiorValues_lag(x, data[[2]])])
#peaks_list <- lapply(peaks_list, function(x) x[, local_mean_diff := data[[2]][data[[2]]$Cell_id == x$Cell_id]$local_mean_diff[1]])
data_peaks <- do.call(rbind, peaks_list)
model <- readRDS("model.rds")
data_peaks[, Prediction := predict(model, data_peaks, type="response")]
data_final <- data_peaks[data_peaks$Prediction > 0.1,]
View(data)
#true_peaks <- PNHRA(data[[1]], data[[2]], range)
#true_peaks <- false_pos(data[[1]], data[[2]], range)
#return(list(true_peaks, data[[2]]))
return(list(data_final, data[[2]],data_peaks))
}
test_best_1Hz <- keep_best_peaks(test_peaks_1Hz, 20)
test_borders_1Hz <- find_borders(test_best_1Hz, 50)
test_borders_1Hz
test_classify_1Hz <- classify_peaks(test_borders_1Hz, time_thresh = 1, frame_rate = 0.25)
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_clean_1Hz, compare_groups = FALSE)
test_resp_1
library(CalQuick)
#' @examples
prepareData <- function(folder_name, stim_number, frame_rate,  duration_in_seconds = 30, compare_groups = FALSE
) {
# Get the file names and store the content in a list of df :
myFiles <- list.files(folder_name, pattern = "\\.csv", recursive = T, full.names = T)
# Removing the meta_data file :
myFiles <- myFiles[!stringr::str_detect(myFiles,pattern="meta")]
meta <- list.files(folder_name, pattern = "meta", recursive = T, full.names = T)
df_list <- vector(mode = "list", length = length(myFiles))
# Reading all the files
df_list <- lapply(myFiles, function(x) data.table::fread(x, skip = 1, header = FALSE))
df_list <- lapply(df_list, function(x) x[,2:length(x)])
df_list <- lapply(df_list, function(x) setnames(x, paste0(rep("Mean", length(x)), seq(1: length(x)))))
# Code pour récupérer uniquement le numéro du coverslip et lui ajouter une lettre :
coverslip_id <- lapply(myFiles, function(x) as.integer(stringr::str_replace_all(stringr::str_split(x, "/")[[1]][4], "[.csv.]", "")))
letter_list <- LETTERS[seq(from = 1, to = length(myFiles))]
coverslip_id <- purrr::map2(letter_list, coverslip_id, function(x,y) paste(x,y,sep =""))
# Fetching the stimuli informations :
meta_df <- data.table::fread(meta)
stimuli <- meta_df$stimuli
stimuli <- split(stimuli, ceiling(seq_along(stimuli)/stim_number))
stimuli <- lapply(stimuli, function(x) purrr::map2(seq_along(1:stim_number), x, function(y, z) paste(y,z, sep=".")))
# now the time informations :
each <- meta_df$timing
each <- split(each, ceiling(seq_along(each)/stim_number))
# Get the pattern to find in the colnames for the cell_srt function :
pattern <- substr(colnames(df_list[[1]])[2], 1,4)
### Code pour récupérer uniquement le groupe auquel appartient un coverslip
group_list <- lapply(myFiles, function(x) stringr::str_split(x, "/")[[1]][2])
if(compare_groups == TRUE) {
for(i in 1:length(df_list)){
# voir pour executer tidy_df sur chaque élément de df_list via un pmap ? :
df_list[[i]] <- tidy_df(df_list[[i]],stimuli[[i]], each[[i]], pattern,
duration_in_seconds, frame_rate, coverslip_id = coverslip_id[[i]], id = i,
multiple = TRUE, compare_groups = TRUE, group_list[[i]])
}
}
if(compare_groups == FALSE) {
for(i in 1:length(df_list)){
df_list[[i]] <- tidy_df(df_list[[i]],stimuli[[i]], each[[i]], pattern, duration_in_seconds, frame_rate, coverslip_id = i, id = i, multiple = TRUE, compare_groups = FALSE, group_list[[i]])
}
}
df <- do.call(rbind, df_list)
#write.csv(df, "df_manip_maxime.csv")
return(df)
}
stim_var <- function(data, stimuli, each, frame_rate, coverslip_id){
frame_list <- list()
time <- purrr::map(each, function(x) as.numeric(x))
# Converting minutes to frames
frame_list <- lapply(time, min_to_f, frame_rate)
frame_list <- append(frame_list, dim(data)[1])
rep_each <- list()
count <- 0
for(i in frame_list){
x <- i - count
count <- count + x
rep_each <- append(rep_each, x)
}
rep_each <- rep_each[-1]
index = 1
stimuli_full <- list()
for (i in stimuli){
stim <- rep(i, rep_each[index])
stimuli_full <- append(stimuli_full, stim)
index = index + 1
}
data$stimulus <- unlist(stimuli_full)
data$coverslip <- rep(coverslip_id, dim(data)[1])
#print("This is for you to verify that each stimulus
#in the new dataframe has been repeated the right number of times:")
#for (i in stimuli){
#print(dim(dplyr::filter(data, stimulus == i))[1])
#}
return(data)
}
#' @examples
cell_sort <- function(df,pat,  duration_in_seconds, frame_rate, id,
multiple = TRUE, compare_groups = TRUE, groups){
stimuli_full <- df$stimulus
coverslip_full <- df$coverslip
df <- dplyr::select(df, dplyr::matches(pat))
dim <- dim(df)
data_fus <- tidyr::gather(df,
key = "Cell_id",
value = "Mean_Grey", 1:dim[2])
data_fus <- data_fus[,c("Cell_id", "Mean_Grey")]
data_fus$Mean_Grey <- unlist(lapply(data_fus$Mean_Grey, function(x) if(is.character(x)) {str_replace_all( x, ",",".")} else{x}))
data_fus$Mean_Grey <- unlist(lapply(data_fus$Mean_Grey, function(x) if(is.character(x)) {as.numeric(x)} else {x}))
#Creating the variable stimulus and adding it to the data
stimuli_final <- unlist(rep(stimuli_full,dim[2]))
coverslip_final <- unlist(rep(coverslip_full,dim[2]))
data_fus$stimulus <- stimuli_final
data_fus$coverslip <- coverslip_final
if(compare_groups == TRUE){
data_fus$group <- rep(groups, dim(data_fus)[1])
}
data_fus$Cell_id <- rep(unlist(createId(data_fus, id)), each = dim[1])
#creating a variable with time frame
frame_vec <- rep(seq(from = 1, to = dim[1]),times = dim[2])
data_fus$time_frame <- frame_vec
# Adding a variable with the actual time in seconds
time_sec <- rep(seq(from = 1/ frame_rate, to = dim[1]/frame_rate, by = 1/frame_rate ),times = dim[2])
data_fus$time_seconds <- time_sec
duration <- duration_in_seconds * frame_rate
# Adding a variable tracking the frame with each stimulus being the zero reference :
data_fus <- data.table::setDT(data_fus)[, Time_frame_stim := seq(c(1:length(stimulus)))]
data_fus <- data_fus[, Stimulation := Time_frame_stim <= duration]
return(data_fus)
}
tidy_df <- function(data, stimuli, each, pattern, duration_in_seconds,
frame_rate, coverslip_id, id, multiple = FALSE, compare_groups = FALSE, groups) {
df_stim <- stim_var(data, stimuli, each, frame_rate, coverslip_id)
df_final <- cell_sort(df_stim, pattern, duration_in_seconds, frame_rate, id = id, multiple = multiple, compare_groups, groups)
return(df_final)
}
#' @examples
prepareData <- function(folder_name, stim_number, frame_rate,  duration_in_seconds = 30, compare_groups = FALSE
) {
# Get the file names and store the content in a list of df :
myFiles <- list.files(folder_name, pattern = "\\.csv", recursive = T, full.names = T)
# Removing the meta_data file :
myFiles <- myFiles[!stringr::str_detect(myFiles,pattern="meta")]
meta <- list.files(folder_name, pattern = "meta", recursive = T, full.names = T)
df_list <- vector(mode = "list", length = length(myFiles))
# Reading all the files
df_list <- lapply(myFiles, function(x) data.table::fread(x, skip = 1, header = FALSE))
df_list <- lapply(df_list, function(x) x[,2:length(x)])
df_list <- lapply(df_list, function(x) setnames(x, paste0(rep("Mean", length(x)), seq(1: length(x)))))
# Code pour récupérer uniquement le numéro du coverslip et lui ajouter une lettre :
coverslip_id <- lapply(myFiles, function(x) as.integer(stringr::str_replace_all(stringr::str_split(x, "/")[[1]][4], "[.csv.]", "")))
letter_list <- LETTERS[seq(from = 1, to = length(myFiles))]
coverslip_id <- purrr::map2(letter_list, coverslip_id, function(x,y) paste(x,y,sep =""))
# Fetching the stimuli informations :
meta_df <- data.table::fread(meta)
stimuli <- meta_df$stimuli
stimuli <- split(stimuli, ceiling(seq_along(stimuli)/stim_number))
stimuli <- lapply(stimuli, function(x) purrr::map2(seq_along(1:stim_number), x, function(y, z) paste(y,z, sep=".")))
# now the time informations :
each <- meta_df$timing
each <- split(each, ceiling(seq_along(each)/stim_number))
# Get the pattern to find in the colnames for the cell_srt function :
pattern <- substr(colnames(df_list[[1]])[2], 1,4)
### Code pour récupérer uniquement le groupe auquel appartient un coverslip
group_list <- lapply(myFiles, function(x) stringr::str_split(x, "/")[[1]][2])
if(compare_groups == TRUE) {
for(i in 1:length(df_list)){
# voir pour executer tidy_df sur chaque élément de df_list via un pmap ? :
df_list[[i]] <- tidy_df(df_list[[i]],stimuli[[i]], each[[i]], pattern,
duration_in_seconds, frame_rate, coverslip_id = coverslip_id[[i]], id = i,
multiple = TRUE, compare_groups = TRUE, group_list[[i]])
}
}
if(compare_groups == FALSE) {
for(i in 1:length(df_list)){
df_list[[i]] <- tidy_df(df_list[[i]],stimuli[[i]], each[[i]], pattern, duration_in_seconds, frame_rate, coverslip_id = i, id = i, multiple = TRUE, compare_groups = FALSE, group_list[[i]])
}
}
df <- do.call(rbind, df_list)
#write.csv(df, "df_manip_maxime.csv")
return(df)
}
test_1Hz_bis <- prepareData("test1_2", 2, 1, compare_groups = FALSE)
VNO <- prepareData("VNO", 5, 0.25, compare_groups = TRUE)
VNO
test_1Hz_bis
library(CalQuick)
library(devtools)
install_github("ETrives/CalQuick", auth_token = « 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 »)
devtools::install_github("ETrives/CalQuick", auth_token = "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 ")
library(CalQuick)
getwd()
setwd("C:/Users/etrives/Documents/R/CalQuick")
test_1Hz_bis <- prepareData("test1_2", 2, 1, compare_groups = FALSE)
test_clean_1Hz <- clean_data(test_1Hz_bis, 0.1, 2, mean_width = 20, DPA_width = 10, mean_width_diff = 10)
test_clean_1Hz
test_back_1Hz <- backEstimate(test_clean_1Hz, method = "gam")
test_back_1Hz
test_norm_1Hz <- norm_df(test_back_1Hz, var = "gam", width = 10)
test_peaks_1Hz <- find_peaks(test_norm_1Hz, threshold = 3, smooth = TRUE)
test_best_1Hz <- keep_best_peaks(test_peaks_1Hz, 20)
devtools::install_github("ETrives/CalQuick", auth_token = "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 ")
devtools::install_github("ETrives/CalQuick", auth_token = "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 ")
setwd("C:/Users/etrives/Documents/R/CalQuick")
test_1Hz_bis <- prepareData("test1_2", 2, 1, compare_groups = FALSE)
library(CalQuick)
test_1Hz_bis <- prepareData("test1_2", 2, 1, compare_groups = FALSE)
test_clean_1Hz <- clean_data(test_1Hz_bis, 0.1, 2, mean_width = 20, DPA_width = 10, mean_width_diff = 10)
test_back_1Hz <- backEstimate(test_clean_1Hz, method = "gam")
test_norm_1Hz <- norm_df(test_back_1Hz, var = "gam", width = 10)
test_peaks_1Hz <- find_peaks(test_norm_1Hz, threshold = 3, smooth = TRUE)
test_best_1Hz <- keep_best_peaks(test_peaks_1Hz, 20)
test_borders_1Hz <- find_borders(test_best_1Hz, 50)
test_classify_1Hz <- classify_peaks(test_borders_1Hz, time_thresh = 1, frame_rate = 0.25)
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_clean_1Hz, compare_groups = FALSE)
test_resp_1
library(devtools)
install_github("ETrives/CalQuick", auth_token = "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")
library(CalQuick)
setwd("C:/Users/etrives/Documents/R/CalQuick")
test_1Hz_bis <- prepareData("test1_2", 2, 1, compare_groups = FALSE)
test_clean_1Hz <- clean_data(test_1Hz_bis, 0.1, 2, mean_width = 20, DPA_width = 10, mean_width_diff = 10)
test_back_1Hz <- backEstimate(test_clean_1Hz, method = "gam")
test_norm_1Hz <- norm_df(test_back_1Hz, var = "gam", width = 10)
test_peaks_1Hz <- find_peaks(test_norm_1Hz, threshold = 3, smooth = TRUE)
test_best_1Hz <- keep_best_peaks(test_peaks_1Hz, 20)
test_borders_1Hz <- find_borders(test_best_1Hz, 50)
test_classify_1Hz <- classify_peaks(test_borders_1Hz, time_thresh = 1, frame_rate = 0.25)
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_clean_1Hz, compare_groups = FALSE)
test_resp_1
#' Analyze_Responses
#'
#' @param data
#' @param df_clean
#' @param compare_groups
#'
#' @return
#' @export
#'
#' @examples
Analyze_Responses <- function(data, df_clean, compare_groups = FALSE){
### Adding a variable "Response" for each stimulus in df_clean
if(compare_groups == FALSE){
d <- unique(df_clean[,c("Cell_id", "stimulus")])
d_list <- split(d,cumsum(1:nrow(d) %in% seq(1:nrow(d))))
d_list <- lapply(d_list, function(x) data.table::setDT(x)[, Response := ifelse(is.na(
test_classify_1Hz[test_classify_1Hz$Cell_id == x$Cell_id &
test_classify_1Hz$Start_peak_stimulus == x$stimulus,]$Cell_id[1]),
FALSE, TRUE) ])
d <- do.call(rbind, d_list)
stim_list <- unique(d$stimulus)
n_cells <- length(unique(d$Cell_id))
n_responders <- sum(d$Response == TRUE)
prop_total <- n_responders / n_cells
n_responses_by_stim <- unlist(lapply(stim_list, function(x) sum(d$stimulus == x & d$Response == TRUE)))
prop_by_stim <- n_responses_by_stim / n_cells
prop_by_stim_responders <- n_responses_by_stim / n_responders
df_final <- data.frame(Stimulus = stim_list)
df_final$Resp <- n_responses_by_stim
df_final$Proportion_of_responders <- prop_by_stim_responders
df_final$Proportion_of_total_cells <- prop_by_stim
d$Response <- ifelse(d$Response == TRUE, 1,0)
res <- Compare_props(d)
}
if(compare_groups == TRUE) {
d <- unique(df_clean[,c("Cell_id", "stimulus", "group")])
d_list <- split(d,cumsum(1:nrow(d) %in% seq(1:nrow(d))))
d_list <- lapply(d_list, function(x) data.table::setDT(x)[, Response := ifelse(is.na(
test_classify_1Hz[test_classify_1Hz$Cell_id == x$Cell_id &
test_classify_1Hz$Start_peak_stimulus == x$stimulus &
test_classify_1Hz$group == x$group,]$Cell_id[1]),
FALSE, TRUE) ])
d <- do.call(rbind, d_list)
View(d)
stim_list <- unique(d$stimulus)
group_list <- unique(d$group)
n_cells <- length(unique(d$Cell_id))
# Proportions totales
n_responders <- sum(d$Response == TRUE)
prop_total <- n_responders / n_cells
#n_responses_by_stim <- unlist(lapply(stim_list, function(x) sum(d$stimulus == x & d$Response == TRUE)))
# prop_by_stim <- n_responses_by_stim / n_cells
# prop_by_stim_responders <- n_responses_by_stim / n_responders
# Réponses par groupe :
n_responses_by_group <- unlist(lapply(group_list, function(x) sum(d$group == x & d$Response == TRUE)))
prop_by_group <- n_responses_by_group / n_cells
resp_by_group_and_stim <- unlist(lapply(group_list, function(x) lapply(stim_list, function(y) sum(d$group == x & d$stimulus == y & d$Response == TRUE))))
prop_by_group_and_stim_responders <- resp_by_group_and_stim / n_responders
prop_by_group_and_stim <- resp_by_group_and_stim / n_cells
df_final <- data.frame(Stimulus = rep(stim_list, times = length(group_list)))
df_final$group <- rep(group_list, each = length(stim_list))
df_final$resp <- resp_by_group_and_stim
#df_final$non_resp <- n_responders - resp_by_group_and_stim
#df_final$non_resp_total_cells <- n_cells - resp_by_group_and_stim
df_final$prop_responders <- prop_by_group_and_stim_responders
df_final$prop_total_cells <- prop_by_group_and_stim
#res <- glmer(Response ~ group * stimulus + (1|Cell_id), family = binomial, data = d)
res <- "NO STATS"
}
#return(list(data_count, data_count_stim[[2]], between_stim[[1]], between_stim[[2]]))
return(list("n_cells" = n_cells, "n_responders" = n_responders, "Proportion" = prop_total, df_final, res))
}
#' Compare_props
#'
#' @param data the full output from Count_responders_stim()
#'
#' @return a list with 2 elements. The first is the general summary of the cochran's q test
#' the second is the results of the pairwise comparisons between stimuli with McNemar test with correction for multiple comparisons
#' @export
#'
#' @examples
Compare_props <- function(data){
res_tot <- rstatix::cochran_qtest(data, Response~stimulus|Cell_id)
res_post_hoc <- rstatix::pairwise_mcnemar_test(data, Response~stimulus|Cell_id)
return(list(res_tot, res_post_hoc))
}
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_clean_1Hz, compare_groups = FALSE)
test_resp_1 <- Analyze_Responses(test_classify_1Hz, df_clean, compare_groups = TRUE)
test_resp_1
#' from the previous step
#'
#'
#' @param data
#' @param range
#'
#' @return
#' @export
#'
#' @examples
find_borders <- function(data, range){
dt_1 <- data[[1]]
dt_2 <- data[[2]]
True_peaks <- dt_1[dt_1$True_peak == TRUE]
# Defining the range in which to find before and after the peak to find the
# start/end
True_peaks$start_window <- unlist(lapply(True_peaks$Max_peak_frame, function(x) x - as.integer(range)))
True_peaks$end_window <- unlist(lapply(True_peaks$Max_peak_frame, function(x) x + as.integer(range)))
# Splitting the first data table into a list of data table with each element
# containing the informations regarding one peak
find_1 <- split(True_peaks,cumsum(1:nrow(True_peaks) %in% seq(1:nrow(True_peaks))))
start_area_list <- find_start(find_1, dt_2, range)
peak_start <- do.call(rbind, start_area_list)
peak_start$Cell_id == start_area_list$Cell_id
end_area_list <- find_end(find_1, dt_2, range)
peak_end <- do.call(rbind, end_area_list)
True_peaks$Start_peak_frame <- peak_start$time_frame
True_peaks$Start_peak_derivative <- peak_start$smooth_Diff
True_peaks$Start_peak_stimulus <- peak_start$stimulus
True_peaks$Start_peak_rel_frame <- peak_start$Time_frame_stim
True_peaks$Start_peak_stimulation <- peak_start$Stimulation
True_peaks$End_peak_frame <- peak_end$time_frame
True_peaks$End_peak_derivative <- peak_end$smooth_Diff
True_peaks$End_peak_frame <- peak_end$time_frame
True_peaks$End_peak_rel_frame <- peak_end$Time_frame_stim
True_peaks$group <- peak_start$group
return(list(True_peaks, peak_start, peak_end))
}
VNO <- prepareData("VNO", 5, 0.25, compare_groups = TRUE)
test_VNO_clean_1Hz <- clean_data(VNO, 0.1, 2, mean_width = 15, DPA_width = 5, mean_width_diff = 5)
test_VNO_back_1Hz <- backEstimate(test_VNO_clean_1Hz, method = "gam")
test_VNO_norm_1Hz <- norm_df(test_VNO_back_1Hz, var = "gam", width = 10)
test_VNO_peaks_1Hz <- find_peaks(test_VNO_norm_1Hz, threshold = 3, smooth = TRUE)
test_VNO_best_1Hz <- keep_best_peaks(test_VNO_peaks_1Hz, 5)
test_borders_1Hz <- find_borders(test_VNO_best_1Hz, 100)
test_classify_1Hz <- classify_peaks(test_borders_1Hz, time_thresh = 1, frame_rate = 0.25)
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_VNO_clean_1Hz, compare_groups = TRUE)
test_resp_1
library(CalQuick)
test_1Hz_bis <- prepareData("test1_2", 2, 1, compare_groups = FALSE)
test_clean_1Hz <- clean_data(test_1Hz_bis, 0.1, 2, mean_width = 20, DPA_width = 10, mean_width_diff = 10)
test_back_1Hz <- backEstimate(test_clean_1Hz, method = "gam")
test_norm_1Hz <- norm_df(test_back_1Hz, var = "gam", width = 10)
test_peaks_1Hz <- find_peaks(test_norm_1Hz, threshold = 3, smooth = TRUE)
test_best_1Hz <- keep_best_peaks(test_peaks_1Hz, 20)
test_borders_1Hz <- find_borders(test_best_1Hz, 50)
test_classify_1Hz <- classify_peaks(test_borders_1Hz, time_thresh = 1, frame_rate = 0.25)
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_clean_1Hz, compare_groups = FALSE)
test_resp_1
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_VNO_clean_1Hz, compare_groups = TRUE)
test_borders_1Hz <- find_borders(test_VNO_best_1Hz, 100)
test_classify_1Hz <- classify_peaks(test_borders_1Hz, time_thresh = 1, frame_rate = 0.25)
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_VNO_clean_1Hz, compare_groups = TRUE)
test_resp_1
test_resp_1 <- Analyze_Responses(test_classify_1Hz, test_VNO_clean_1Hz, compare_groups = FALSE)
test_resp_1
#' Analyze_Responses
#'
#' @param data
#' @param df_clean
#' @param compare_groups
#'
#' @return
#' @export
#'
#' @examples
Analyze_Responses <- function(data, df_clean, compare_groups = FALSE){
### Adding a variable "Response" for each stimulus in df_clean
if(compare_groups == FALSE){
d <- unique(df_clean[,c("Cell_id", "stimulus")])
d_list <- split(d,cumsum(1:nrow(d) %in% seq(1:nrow(d))))
d_list <- lapply(d_list, function(x) data.table::setDT(x)[, Response := ifelse(is.na(
test_classify_1Hz[test_classify_1Hz$Cell_id == x$Cell_id &
test_classify_1Hz$Start_peak_stimulus == x$stimulus,]$Cell_id[1]),
FALSE, TRUE) ])
d <- do.call(rbind, d_list)
stim_list <- unique(d$stimulus)
n_cells <- length(unique(d$Cell_id))
n_responders <- sum(d$Response == TRUE)
prop_total <- n_responders / n_cells
n_responses_by_stim <- unlist(lapply(stim_list, function(x) sum(d$stimulus == x & d$Response == TRUE)))
prop_by_stim <- n_responses_by_stim / n_cells
prop_by_stim_responders <- n_responses_by_stim / n_responders
df_final <- data.frame(Stimulus = stim_list)
df_final$Resp <- n_responses_by_stim
df_final$Proportion_of_responders <- prop_by_stim_responders
df_final$Proportion_of_total_cells <- prop_by_stim
d$Response <- ifelse(d$Response == TRUE, 1,0)
res <- Compare_props(d)
}
if(compare_groups == TRUE) {
d <- unique(df_clean[,c("Cell_id", "stimulus", "group")])
d_list <- split(d,cumsum(1:nrow(d) %in% seq(1:nrow(d))))
d_list <- lapply(d_list, function(x) data.table::setDT(x)[, Response := ifelse(is.na(
test_classify_1Hz[test_classify_1Hz$Cell_id == x$Cell_id &
test_classify_1Hz$Start_peak_stimulus == x$stimulus &
test_classify_1Hz$group == x$group,]$Cell_id[1]),
FALSE, TRUE) ])
d <- do.call(rbind, d_list)
stim_list <- unique(d$stimulus)
group_list <- unique(d$group)
n_cells <- length(unique(d$Cell_id))
# Proportions totales
n_responders <- sum(d$Response == TRUE)
prop_total <- n_responders / n_cells
#n_responses_by_stim <- unlist(lapply(stim_list, function(x) sum(d$stimulus == x & d$Response == TRUE)))
# prop_by_stim <- n_responses_by_stim / n_cells
# prop_by_stim_responders <- n_responses_by_stim / n_responders
# Réponses par groupe :
n_responses_by_group <- unlist(lapply(group_list, function(x) sum(d$group == x & d$Response == TRUE)))
prop_by_group <- n_responses_by_group / n_cells
resp_by_group_and_stim <- unlist(lapply(group_list, function(x) lapply(stim_list, function(y) sum(d$group == x & d$stimulus == y & d$Response == TRUE))))
prop_by_group_and_stim_responders <- resp_by_group_and_stim / n_responders
prop_by_group_and_stim <- resp_by_group_and_stim / n_cells
df_final <- data.frame(Stimulus = rep(stim_list, times = length(group_list)))
df_final$group <- rep(group_list, each = length(stim_list))
df_final$resp <- resp_by_group_and_stim
#df_final$non_resp <- n_responders - resp_by_group_and_stim
#df_final$non_resp_total_cells <- n_cells - resp_by_group_and_stim
df_final$prop_responders <- prop_by_group_and_stim_responders
df_final$prop_total_cells <- prop_by_group_and_stim
#res <- glmer(Response ~ group * stimulus + (1|Cell_id), family = binomial, data = d)
res <- "NO STATS"
}
#return(list(data_count, data_count_stim[[2]], between_stim[[1]], between_stim[[2]]))
return(list("n_cells" = n_cells, "n_responders" = n_responders, "Proportion" = prop_total, df_final, res))
}
test_VNO_best_1Hz <- keep_best_peaks(test_VNO_peaks_1Hz, 5)
#' keep_best_peaks
#'
#' @param data the whole output from find_peaks function
#' @param range
#'
#' @return the same objects with an added column named True_Peaks which is TRUE if the peak is kept, FALSE if not
#' @export
#'
#' @examples
keep_best_peaks <- function(data, range){
data[[1]] <- data.table::setDT(data[[1]])[, True_peak := Max_peak_smooth_z == max(Max_peak_smooth_z), by = list(Cell_id, Max_peak_stimulus)]
data[[2]] <- data.table::setDT(data[[2]])[, True_peak := smooth_z == max(smooth_z), by = list(Cell_id, stimulus)]
peaks_data  <- data[[1]][data[[1]]$True_peak == TRUE,]
peaks_list <- split(peaks_data,cumsum(1:nrow(peaks_data) %in% seq(1:nrow(peaks_data))))
#peaks_list <- lapply(peaks_data, function(x) x[, triangleRatio := triangleRatio(full_data, x)])
#peaks_list <- lapply(peaks_list, function(x)  x[, triangleRatio := triangleRatio(data[[2]], x)[[1]]])
#peaks_list <- lapply(peaks_list, function(x) x[, trianglePoints :=  triangleRatio(data[[2]], x)[2]])
#peaks_list <- lapply(peaks_list, function(x) x[, posArea :=  triangleRatio(data[[2]], x)[3]])
#peaks_list <- lapply(peaks_list, function(x) x[, negArea :=  triangleRatio(data[[2]], x)[4]])
peaks_list <- lapply(peaks_list, function(x) x[, infValue :=  inferiorValues(x, data[[2]])])
peaks_list <- lapply(peaks_list, function(x) x[, bimod_peak :=  bimodal_cell(x, data[[2]])])
#peaks_list <- lapply(peaks_list, function(x) x[, infValue_D :=  inferiorValues_lag(x, data[[2]])])
#peaks_list <- lapply(peaks_list, function(x) x[, infValue_D :=  inferiorValues_lag(x, data[[2]])])
#peaks_list <- lapply(peaks_list, function(x) x[, local_mean_diff := data[[2]][data[[2]]$Cell_id == x$Cell_id]$local_mean_diff[1]])
data_peaks <- do.call(rbind, peaks_list)
model <- readRDS("model.rds")
data_peaks[, Prediction := predict(model, data_peaks, type="response")]
data_final <- data_peaks[data_peaks$Prediction > 0.1,]
#data_final <- data_peaks
#true_peaks <- PNHRA(data[[1]], data[[2]], range)
#true_peaks <- false_pos(data[[1]], data[[2]], range)
#return(list(true_peaks, data[[2]]))
return(list(data_final, data[[2]],data_peaks))
}
test_VNO_best_1Hz <- keep_best_peaks(test_VNO_peaks_1Hz, 5)
